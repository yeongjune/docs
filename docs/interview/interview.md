# 数据库分区、分表、分库、分片

## 分区的概念
数据分区是一种物理数据库的设计技术，它的目的是为了在特定的SQL操作中减少数据读写的总量以缩减响应时间。
分区并不是生成新的数据表，而是将表的数据均衡分摊到不同的硬盘，系统或是不同服务器存储介子中，实际上还是一张表。另外，分区可以做到将表的数据均衡到不同的地方，提高数据检索的效率，降低数据库的频繁IO压力值，分区的优点如下：
1、相对于单个文件系统或是硬盘，分区可以存储更多的数据；
2、数据管理比较方便，比如要清理或废弃某年的数据，就可以直接删除该日期的分区数据即可；
3、精准定位分区查询数据，不需要全表扫描查询，大大提高数据检索效率；
4、可跨多个分区磁盘查询，来提高查询的吞吐量；
5、在涉及聚合函数查询时，可以很容易进行数据的合并；


## 分类 （row 行 ，column 列）
1、水平分区
这种形式分区是对表的行进行分区，通过这样的方式不同分组里面的物理列分割的数据集得以组合，从而进行个体分割（单分区）或集体分割（1个或多个分区）。所有在表中定义的列在每个数据集中都能找到，所以表的特性依然得以保持。
举个简单例子：一个包含十年发票记录的表可以被分区为十个不同的分区，每个分区包含的是其中一年的记录。（朋奕注：这里具体使用的分区方式我们后面再说，可以先说一点，一定要通过某个属性列来分割，譬如这里使用的列就是年份）
2、垂直分区
这种分区方式一般来说是通过对表的垂直划分来减少目标表的宽度，使某些特定的列被划分到特定的分区，每个分区都包含了其中的列所对应的行。
举个简单例子：一个包含了大text和BLOB列的表，这些text和BLOB列又不经常被访问，这时候就要把这些不经常使用的text和BLOB了划分到另一个分区，在保证它们数据相关性的同时还能提高访问速度。
在数据库供应商开始在他们的数据库引擎中建立分区（主要是水平分区）时，DBA和建模者必须设计好表的物理分区结构，不要保存冗余的数据（不同表中同时都包含父表中的数据）或相互联结成一个逻辑父对象（通常是视图）。这种做法会使水平分区的大部分功能失效，有时候也会对垂直分区产生影响。

## 分区、分表、分库的详细理解
分区
就是把一张表的数据分成N个区块，在逻辑上看最终只是一张表，但底层是由N个物理区块组成的

分表
就是把一张表按一定的规则分解成N个具有独立存储空间的实体表。系统读写时需要根据定义好的规则得到对应的字表明，然后操作它。

分库
一旦分表，一个库中的表会越来越多

将整个数据库比作图书馆，一张表就是一本书。当要在一本书中查找某项内容时，如果不分章节，查找的效率将会下降。而同理，在数据库中就是分区。

# 缓存技术
缓存是分布式系统中的重要组件，主要解决高并发，大数据场景下，热点数据访问的性能问题。提供高性能的数据快速访问。

## 缓存的原理
将数据写入/读取速度更快的存储（设备）；
将数据缓存到离应用最近的位置；
将数据缓存到离用户最近的位置。

## 缓存分类
在分布式系统中，缓存的应用非常广泛，从部署角度有以下几个方面的缓存应用。
CDN缓存；
反向代理缓存；
分布式Cache；
本地应用缓存；

## 缓存媒介
常用中间件：Varnish，Ngnix，Squid，Memcache，Redis，Ehcache等；
缓存的内容：文件，数据，对象；
缓存的介质：CPU，内存（本地，分布式），磁盘（本地，分布式）

## 代理缓存比较

常用的代理缓存有Varnish，Squid，Ngnix，简单比较如下：
（1）varnish和squid是专业的cache服务，nginx需要第三方模块支持；
（2） Varnish采用内存型缓存，避免了频繁在内存、磁盘中交换文件，性能比Squid高；
（3）Varnish由于是内存cache，所以对小文件如css,js,小图片啥的支持很棒，后端的持久化缓存可以采用的是Squid或ATS；
（4）Squid功能全而大，适合于各种静态的文件缓存，一般会在前端挂一个HAProxy或nginx做负载均衡跑多个实例；
（5）Nginx采用第三方模块ncache做的缓冲，性能基本达到varnish，一般作为反向代理使用，可以实现简单的缓存。


# 乐观锁和悲观锁
乐观锁
在关系数据库管理系统里，乐观并发控制（又名”乐观锁”，Optimistic Concurrency Control，缩写”OCC”）是一种并发控制的方法。它假设多用户并发的事务在处理时不会彼此互相影响，各事务能够在不产生锁的情况下处理各自影响的 那部分数据。在提交数据更新之前，每个事务会先检查在该事务读取数据后，有没有其他事务又修改了该数据。如果其他事务有更新的话，正在提交的事务会进行回滚。乐观事务控制最早是由孔祥重（H.T.Kung）教授提出。
乐观并发控制的事务包括以下阶段： 
1. 读取：事务将数据读入缓存，这时系统会给事务分派一个时间戳。 
2. 校验：事务执行完毕后，进行提交。这时同步校验所有事务，如果事务所读取的数据在读取之后又被其他事务修改，则产生冲突，事务被中断回滚。 
3. 写入：通过校验阶段后，将更新的数据写入数据库。
乐观并发控制多数用于数据争用不大、冲突较少的环境中，这种环境中，偶尔回滚事务的成本会低于读取数据时锁定数据的成本，因此可以获得比其他并发控制方法更高的吞吐量。
相对于悲观锁，在对数据库进行处理的时候，乐观锁并不会使用数据库提供的锁机制。一般的实现乐观锁的方式就是记录数据版本。
数据版本,为数据增加的一个版本标识。当读取数据时，将版本标识的值一同读出，数据每更新一次，同时对版本标识进行更新。当我们提交更新的时候，判断数据库表对应记录的当前版本信息与第一次取出来的版本标识进行比对，如果数据库表当前版本号与第一次取出来的版本标识值相等，则予以更新，否则认为是过期数据。
实现数据版本有两种方式，第一种是使用版本号，第二种是使用时间戳。 
使用版本号实现乐观锁
使用版本号时，可以在数据初始化时指定一个版本号，每次对数据的更新操作都对版本号执行+1操作。并判断当前版本号是不是该数据的最新的版本号。

优点与不足
乐观并发控制相信事务之间的数据竞争(data race)的概率是比较小的，因此尽可能直接做下去，直到提交的时候才去锁定，所以不会产生任何锁和死锁。但如果直接简单这么做，还是有可能会遇到不可预 期的结果，例如两个事务都读取了数据库的某一行，经过修改以后写回数据库，这时就遇到了问题。

悲观锁
在关系数据库管理系统里，悲观并发控制（又名”悲观锁”，Pessimistic Concurrency Control，缩写”PCC”）是一种并发控制的方法。它可以阻止一个事务以影响其他用户的方式来修改数据。如果一个事务执行的操作读某行数据应用了锁，那只有当这个事务把锁释放，其他事务才能够执行与该锁冲突的操作。
悲观并发控制主要用于数据争用激烈的环境，以及发生并发冲突时使用锁保护数据的成本要低于回滚事务的成本的环境中。

MySQL InnoDB中使用悲观锁
要使用悲观锁，我们必须关闭mysql数据库的自动提交属性，因为MySQL默认使用autocommit模式，也就是说，当你执行一个更新操作后，MySQL会立刻将结果进行提交。set autocommit=0;

上面的查询语句中，我们使用了select…for update的方式，这样就通过开启排他锁的方式实现了悲观锁。此时在t_goods表中，id为1的 那条数据就被我们锁定了，其它的事务必须等本次事务提交之后才能执行。这样我们可以保证当前的数据不会被其它事务修改。

上面我们提到，使用select…for update会把数据给锁住，不过我们需要注意一些锁的级别，MySQL InnoDB默认行级锁。行级锁都是基于索引的，如果一条SQL语句用不到索引是不会使用行级锁的，会使用表级锁把整张表锁住，这点需要注意。

优点与不足
悲观并发控制实际上是”先取锁再访问”的保守策略，为数据处理的安全提供了保证。但是在效率方面，处理加锁的机制会让数据库产生额外的开销，还有增加产生死锁的机会；另外，在只读型事务处理中由于不会产生冲突，也没必要使用锁，这样做只能增加系统负载；还有会降低了并行性，一个事务如果锁定了某行数据，其他事务就必须等待该事务处理完才可以处理那行数

总结
乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库如果提供类似于write_condition机智的其实都是提供的乐观锁。 相反，如果经常发生冲突，上层应用会不断进行 retry，这样反而降低了性能，所以这种情况下用悲观锁比较合适
https://www.cnblogs.com/qlqwjy/p/7798266.html

# 消息队列Kafka、RocketMQ、RabbitMQ 
当下比较知名的消息引擎，包括：
1. ZeroMQ
2. 推特的Distributedlog
3. ActiveMQ：Apache旗下的老牌消息引擎
4. RabbitMQ、Kafka：AMQP的默认实现。
5. RocketMQ
6. Artemis：Apache的ActiveMQ下的子项目
7. Apollo：同样为Apache的ActiveMQ的子项目的号称下一代消息引擎
8. 商业化的消息引擎IronMQ
9. 以及实现了JMS(Java Message Service)标准的OpenMQ。
MQ消息队列的技术应用

1.解耦
解耦是消息队列要解决的最本质问题。
2.最终一致性
最终一致性指的是两个系统的状态保持一致，要么都成功，要么都失败。
最终一致性不是消息队列的必备特性，但确实可以依靠消息队列来做最终一致性的事情。
3.广播
消息队列的基本功能之一是进行广播。
有了消息队列，我们只需要关心消息是否送达了队列，至于谁希望订阅，是下游的事情，无疑极大地减少了开发和联调的工作量。
4.错峰与流控
典型的使用场景就是秒杀业务用于流量削峰场景。


Kafka、RocketMQ、RabbitMQ比较
特性	ActiveMQ	RabbitMQ	RocketMQ	Kafka
开发语言	java	erlang	java	scala
单机吞吐量	万级	万级	10万级	10万级
时效性	毫秒级	微秒级	毫秒级	毫秒级以内
可用性	高
（主从架构）	高
（主从架构）	非常高
（分布式架构）	非常高
（分布式架构）
功能特性	成熟的产品，在很多公司得到应用。
有较多的文档
各种协议支持较好	基于erlang开发，并发能力很强，性能及其好，延时很低，管理界面较丰富	MQ功能比较完备，扩展性佳。	只支持主要的MQ功能，像一些消息查询，消息回溯等功能没有提供。是为大数据准备的。







1.ActiveMQ
优点
单机吞吐量：万级
topic数量都吞吐量的影响：
时效性：ms级
可用性：高，基于主从架构实现高可用性
消息可靠性：有较低的概率丢失数据
功能支持：MQ领域的功能极其完备
缺点:
官方社区现在对ActiveMQ 5.x维护越来越少，较少在大规模吞吐的场景中使用。

2.Kafka
号称大数据的杀手锏，谈到大数据领域内的消息传输，则绕不开Kafka，这款为大数据而生的消息中间件，以其百万级TPS的吞吐量名声大噪，迅速成为大数据领域的宠儿，在数据采集、传输、存储的过程中发挥着举足轻重的作用。
Apache Kafka它最初由LinkedIn公司基于独特的设计实现为一个分布式的提交日志系统( a distributed commit log)，之后成为Apache项目的一部分。
目前已经被LinkedIn，Uber, Twitter, Netflix等大公司所采纳。
优点
性能卓越，单机写入TPS约在百万条/秒，最大的优点，就是吞吐量高。
时效性：ms级
可用性：非常高，kafka是分布式的，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用
消费者采用Pull方式获取消息, 消息有序, 通过控制能够保证所有消息被消费且仅被消费一次;
有优秀的第三方Kafka Web管理界面Kafka-Manager；
在日志领域比较成熟，被多家公司和多个开源项目使用；
功能支持：功能较为简单，主要支持简单的MQ功能，在大数据领域的实时计算以及日志采集被大规模使用
缺点：
Kafka单机超过64个队列/分区，Load会发生明显的飙高现象，队列越多，load越高，发送消息响应时间变长
使用短轮询方式，实时性取决于轮询间隔时间；
消费失败不支持重试；
支持消息顺序，但是一台代理宕机后，就会产生消息乱序；
社区更新较慢；

3.RabbitMQ
RabbitMQ 2007年发布，是一个在AMQP(高级消息队列协议)基础上完成的，可复用的企业消息系统，是当前最主流的消息中间件之一。
RabbitMQ优点：
由于erlang语言的特性，mq 性能较好，高并发；
吞吐量到万级，MQ功能比较完备 
健壮、稳定、易用、跨平台、支持多种语言、文档齐全；
开源提供的管理界面非常棒，用起来很好用。社区活跃度高；
RabbitMQ缺点：
erlang开发，很难去看懂源码，基本职能依赖于开源社区的快速维护和修复bug，不利于做二次开发和维护。
RabbitMQ确实吞吐量会低一些，这是因为他做的实现机制比较重。
需要学习比较复杂的接口和协议，学习和维护成本较高。

4.RocketMQ
RocketMQ出自 阿里公司的开源产品，用 Java 语言实现，在设计时参考了 Kafka，并做出了自己的一些改进。
RocketMQ在阿里集团被广泛应用在订单，交易，充值，流计算，消息推送，日志流式处理，binglog分发等场景。
RocketMQ优点：
单机吞吐量：十万级
可用性：非常高，分布式架构
消息可靠性：经过参数优化配置，消息可以做到0丢失
功能支持：MQ功能较为完善，还是分布式的，扩展性好
支持10亿级别的消息堆积，不会因为堆积导致性能下降
源码是java，我们可以自己阅读源码，定制自己公司的MQ，可以掌控
RocketMQ缺点：
支持的客户端语言不多，目前是java及c++，其中c++不成熟；
社区活跃度一般
没有在 mq 核心中去实现JMS等接口，有些系统要迁移需要修改大量代码

消息队列选择建议
1.Kafka
Kafka主要特点是基于Pull的模式来处理消息消费，追求高吞吐量，一开始的目的就是用于日志收集和传输，适合产生大量数据的互联网服务的数据收集业务。
大型公司建议可以选用，如果有日志采集功能，肯定是首选kafka了。

2.RocketMQ
天生为金融互联网领域而生，对于可靠性要求很高的场景，尤其是电商里面的订单扣款，以及业务削峰，在大量交易涌入时，后端可能无法及时处理的情况。
RoketMQ在稳定性上可能更值得信赖，这些业务场景在阿里双11已经经历了多次考验，如果你的业务有上述并发场景，建议可以选择RocketMQ。

3.RabbitMQ
RabbitMQ :结合erlang语言本身的并发优势，性能较好，社区活跃度也比较高，但是不利于做二次开发和维护。不过，RabbitMQ的社区十分活跃，可以解决开发过程中遇到的bug。
如果你的数据量没有那么大，小公司优先选择功能比较完备的RabbitMQ。


# 秒杀系统设计思路
一、限流与降级
客户端限流
按钮置灰
js控制每秒只能发送一个请求
站点层限流
1. Nginx限流
Nginx官方版本限制IP的连接和并发分别有两个模块：

limit_req_zone： 用来限制单位时间内的请求数，即速率限制,采用的漏桶算法。
limit_req_conn： 用来限制同一时间连接数，即并发限制。
2. 站点层限流
客户端限流一般可以限制住普通用户，对于高端用户，则可能使用脚本刷，或者实际抢购的用户量确实大，故需要在站点层进行限流，如单个部署实例的每秒最大请求数，每个用户每秒的最大请求或者通过Redis记录和限制单个用户只能请求一次。

写流量
根据uuid限制每个用户每秒只能一个请求，如使用guava的RateLimiter在进程限流，故如果多个节点，则每个用户可请求数量实际是节点个数倍；或者通过Nginx将相同的uuid转发到相同的机器上面。
读流量：
页面缓存和页面数据缓存。页面缓存可以是进程缓存，页面数据缓存一般是分布式缓存，保持各节点的数据一致性，如库存数量可以放到分布式缓存中。
降级
如果流量太大，导致站点层限流后还是出现问题挂了或者站点层没问题，队列出问题了，则需要采取降级策略。
对于站点层出问题，则可以在客户端直接提示“服务器繁忙，稍后再试”。
对于队列挂了或者Redis挂了无法读取到库存信息，则可以在站点层降级处理，直接返回和提示“抢购人数太多，请稍后尝试”。
二、队列削峰
通过第一步限流后，将合法流量放到一个队列中，实现流量削峰，达到流量可控和异步处理。
入队条件
秒杀的数量有限，所以不需要将第一步限流中成功通过的所有请求都放到队列中，而是可以先将库存数量放到分布式缓存中，如Redis，然后先检查库存是否还有，即数量大于0：
有则扣减库存，则将该请求放到队列中，注意这里存在读数量get，递减数量两个过程，故分布式里面存在并发问题，即两个机器同时读都是100，都递减1，写回99，则其实是减了2，所以这里的数字不是精确的，即放到队列的数据是大于100的，不过具体下单扣减是在后台服务消费队列时使用，故该并发问题对秒杀来说问题不大。如果需要保证一致，则可以使用Redis实现一个分布式锁，即setnx的使用，不过秒杀系统不需要，否则并发量会急剧下降。(这里有给疑问：库存应该什么时候递减呢？)
否则库存不足，直接返回抢购完毕，或者可以优化一下说“抢购完毕，如果有小伙伴放弃，可以继续抢购”来避免队列消息处理失败导致还有没卖完。
请求响应
入队成功或者失败都可以将该请求直接返回了，不过页面可以显示等待中或者提示抢购结果稍后通知，如现在很多抢票都是这样的。(预抢购，稍后执行逻辑吗？)
三、服务层异步处理
服务层消费队列的数据，由于此时速度是可控的，故可以起一个后台服务节点即可，这个后台服务可以使用一个线程来执行这个操作就可以了，这样就不存在竞争问题。如果需要多个后台服务或者多个线程，则可以依赖数据库的自身的锁即可，如乐观锁，来解决并发问题。
（猜测：会不会出现脏数据？ 出现脏数据采用cas来写数据？ 跟下面有冲突，）
所以由该后台服务消费队列的数据，进行下单操作，递减数据库库存。
如果消费队列的某个数据失败，可以采用fail-fast的原则，直接提示失败，不需要进行重试之类的复杂操作。(这里有个疑问：使用mq？)
四、抢购结果通知
由于使用了队列来异步处理，即入队后或者库存不足无法入队，该次抢购请求是直接返回了的，故对于抢购结果是需要进行额外通知的。
1. 客户端轮询
可以通过客户端定时请求服务端，如每秒发送一个请求，如果成功，则提示抢购成功；失败，则返回失败。例如，客户端可以在没有轮询到处理结果时提示“抢购中，请耐心等待”，如果轮询到结果则提示成功或失败。（轮询...并发量可能贼大，把结果放到redis里面，只读redis）
2. 消息推送
另外一种方式可以是直接通过消息推送的方式来通知用户抢购结果。（这个要怎么实现呢~）
完整架构示意图

其中站点层也就是web网关层，提供web API接口，如上图的站点1、2、3是一个 Web 网关集群的多个部署节点，通过 Nginx 来进行负载均衡实现请求的分发。(其实这里我有个疑问，就是nginx扛得住吗？我研究研究nginx先。)


# 高并发秒杀系统如何设计与优化
如今处在一个大数据时代，应届生找工作面试高级Java开发工程师时，经常会被问一些和大数据相关的问题，比如大数据处理问题、高并发处理问题、数据优化问题等，笔者曾经遇到两个比较经典的问题，高并发秒杀系统的设计优化问题和大数据文件排序问题。在这里总结了高并发秒杀系统的设计和优化点。 

面试官常问的问题有：
简单说一下秒杀系统的设计思路?
你怎么实现秒杀业务的？
你怎么保证秒杀成功的？
秒杀操作的策略是什么？
你使用的Redis有什么用？
你为什么使用Redis中间件？
你测试过你这个系统的抗压能力么？
你使用过什么方法来测试你的系统并发量？
你觉得你这个系统还可以再优化么？
你觉得你这个系统的瓶颈在哪里？还可以在哪些方向做进一步优化?

 准备思路是：
 功能模块划分=》秒杀策略=》自己的优化点=》工具测试抗压=》别人提供的优化方法和秒杀策略

1 秒杀系统特点
 秒杀业务简单，卖家查询，买家下订单减库存。
秒杀时网站访问流量激增，出现峰值；
访问请求数量远大于实际需求量。

2 架构设计优化方案
1 秒杀系统架构设计优化
        一个常规的秒杀系统从前到后，依次有：
       前端浏览器秒杀页面=》中间代理服务=》后端服务层=》数据库层

      根据这个流程，一般优化设计思路：将请求拦截在系统上游，降低下游压力。在一个并发量大，实际需求小的系统中，应当尽量在前端拦截无效流量，降低下游服务器和数据库的压力，不然很可能造成数据库读写锁冲突，甚至导致死锁，最终请求超时。 
整体设计思路和优化点：
限流：屏蔽掉无用的流量，允许少部分流量流向后端。
削峰：瞬时大流量峰值容易压垮系统，解决这个问题是重中之重。常用的消峰方法有异步处理、缓存和消息中间件等技术。
异步处理：秒杀系统是一个高并发系统，采用异步处理模式可以极大地提高系统并发量，其实异步处理就是削峰的一种实现方式。
内存缓存：秒杀系统最大的瓶颈一般都是数据库读写，由于数据库读写属于磁盘IO，性能很低，如果能够把部分数据或业务逻辑转移到内存缓存，效率会有极大地提升。
可拓展：当然如果我们想支持更多用户，更大的并发，最好就将系统设计成弹性可拓展的，如果流量来了，拓展机器就好了。像淘宝、京东等双十一活动时会增加大量机器应对交易高峰。
消息队列：消息队列可以削峰，将拦截大量并发请求，这也是一个异步处理过程，后台业务根据自己的处理能力，从消息队列中主动的拉取请求消息进行业务处理。
充分利用缓存：利用缓存可极大提高系统读写速度。 
2详细方案
2.1 前端方案
静态资源缓存：将活动页面上的所有可以静态的元素全部静态化，尽量减少动态元素；通过CDN缓存静态资源，来抗峰值。 
禁止重复提交：用户提交之后按钮置灰，禁止重复提交 
用户限流：在某一时间段内只允许用户提交一次请求，比如可以采取IP限流(有点疑问)
2.2 中间代理层
 可利用负载均衡（例如反向代理Nginx等）使用多个服务器并发处理请求，减小服务器压力。
2.3 后端方案
控制层(网关层)
限制同一UserID访问频率：尽量拦截浏览器请求，但针对某些恶意攻击或其它插件，在服务端控制层需要针对同一个访问uid，限制访问频率。
服务层
当用户量非常大的时候，拦截流量后的请求访问量还是非常大，此时仍需进一步优化。
1.业务分离:将秒杀业务系统和其他业务分离，单独放在高配服务器上，可以集中资源对访问请求抗压。
2.采用消息队列缓存请求：将大流量请求写到消息队列缓存，利用服务器根据自己的处理能力主动到消息缓存队列中抓取任务处理请求，数据库层订阅消息减库存，减库存成功的请求返回秒杀成功，失败的返回秒杀结束。
3.利用缓存应对读请求：对于读多写少业务，大部分请求是查询请求，所以可以读写分离，利用缓存分担数据库压力。
4.利用缓存应对写请求：缓存也是可以应对写请求的，可把数据库中的库存数据转移到Redis缓存中，所有减库存操作都在Redis中进行，然后再通过后台进程把Redis中的用户秒杀请求同步到数据库中。
2.4 数据库层
        数据库层是最脆弱的一层，一般在应用设计时在上游就需要把请求拦截掉，数据库层只承担“能力范围内”的访问请求。所以，上面通过在服务层引入队列和缓存，让最底层的数据库高枕无忧。
       如果不使用缓存来作为中间缓冲而是直接访问数据库的话，可以对数据库进行优化，减少数据库压力。
       对于秒杀系统，直接访问数据库的话，存在一个【事务竞争优化】问题，可使用存储过程（或者触发器）等技术绑定操作，整个事务在MySQL端完成，把整个热点执行放在一个过程当中一次性完成，可以屏蔽掉网络延迟时间，减少行级锁持有时间，提高事务并发访问速度。

2.5 其他秒杀策略
减少硬件开销的策略 ：

       策略1：消息队列缓存请求，按照队列模型取任务执行，秒杀完毕即终止到秒杀结束页面。
       策略2：使用数组为并发请求随机分配秒杀状态（成功和失败），然后将分配到失败状态的请求派发到秒杀失败的页面，分到成功状态的用户在慢慢的按顺序执行秒杀操作；（如果处理失败了可以利用日志来查找具体秒杀失败的商品和用户，执行补救措施或者从其他用户中拿取一个来执行秒杀操作）
       策略3：类似于策略2，不过是用数组为用户分配秒杀资格，将大流量的用户限制为小流量的用户，得到秒杀资格的去执行秒杀，得不到秒杀资格的跳到秒杀失败页面。 (haha,可以有)

（分配状态或分配秒杀资格的策略：（数组状态密度不同，由前到后逐渐稀疏，可以让先到的在前面随机分配，后到的在后面随机分配）根据先到的时间）

3 案例：利用消息中间件和Redis缓存实现
       Redis是一个分布式缓存系统，支持多种数据结构，可利用Redis轻松实现一个强大的秒杀系统。
       我们可以采用Redis 最简单的key-value数据结构，用一个原子类型的变量值(AtomicInteger)作为key，把用户id作为value，库存数量便是原子变量的最大值。对于每个用户的秒杀，我们使用 RPUSH key value插入秒杀请求， 当插入的秒杀请求数达到上限时，停止所有后续插入。
       然后我们可以再启动多个工作线程，使用 LPOP key 读取秒杀成功者的用户id，然后再操作数据库做最终的下订单减库存操作。
       当然，上面Redis也可以替换成消息中间件如ActiveMQ、RabbitMQ等，也可以将缓存和消息中间件 组合起来，缓存系统负责接收记录用户请求，消息中间件负责将缓存中的请求同步到数据库。
 

（1）使用Redis中间件缓存动态资源的好处？
       提高访问速度，减少对数据库的链接的打开、关闭，
（2）为什么不用JVM内存而使用Redis作为缓存呢？
      JVM 内存较小，隔一段时间会自动进行垃圾回收。
      JVM和业务程序绑定在一起了，如果程序出错，JVM也会停止，这样就导致缓存数据丢失。
      如果使用Redis，除了缓存比较大之外，还实现了缓存数据和业务程序的分离，即使运行程序出现错误，也不会影响缓存。
3 压力测试
使用JMeter 压测工具
下载、安装、进入C:/JMeter/bin下面的jmeter.bat批处理文件来启动JMeter的可视化界面，
进入测试计划添加线程组: 设置线程数，循环次数，添加HTTP默认请求，服务器名称，IP，以及自己设定的携带参数
添加监听器，存放测试结果：聚合报告，可以表格查询、图形结果、树结果
点击运行-》启动。
并发量:50W-100W    100W-500W
